{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from src.sumformer import *\n",
    "from src.data_representation import Batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Batched version of the sumformer\n",
    "\"\"\"\n",
    "from typing import Literal\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from ml_lib.models.layers import MLP, Repeat, ResidualShortcut\n",
    "from src.basic import MLP\n",
    "from src.combinators import ResidualShortcut, Repeat\n",
    "from torch_geometric.nn.aggr import Aggregation, SumAggregation\n",
    "from torch_geometric.nn.resolver import aggregation_resolver\n",
    "\n",
    "from src.data_representation import Batch\n",
    "\n",
    "import functools as ft\n",
    "import itertools as it # pyright: ignore\n",
    "from inspect import signature\n",
    "\n",
    "\n",
    "class ResidualShortcut(nn.Module):\n",
    "    \"\"\"Residual shortcut as used in ResNet.\n",
    "\n",
    "    A module that adds the input to the output of another module.\n",
    "    So if inner module is f, the output is x + f(x).\n",
    "    \n",
    "    This is useful to implement residual blocks as they were \n",
    "    originally used in resnet (and are used in a lot of modern architectures)\n",
    "    \"\"\"\n",
    "    inner_module: nn.Module\n",
    "    def __init__(self, inner_module):\n",
    "        super().__init__()\n",
    "        self.inner_module = inner_module\n",
    "        print(self.inner_module)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.inner_module(x)\n",
    "        return x + y\n",
    "\n",
    "class Sequential(nn.Module):\n",
    "    \"\"\"Sequential implementation that allows for more than one input and output.\"\"\"\n",
    "    sub_modules: nn.ModuleList\n",
    "    def __init__(self, *modules: nn.Module):\n",
    "        super().__init__()\n",
    "        self.sub_modules = nn.ModuleList(modules) \n",
    "        print(self.sub_modules)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        output = self.sub_modules[0](*args, **kwargs)\n",
    "        for module in self.sub_modules[1:]:\n",
    "            prev_output = output\n",
    "            match prev_output, signature(module.forward).parameters.items():\n",
    "                case x, [(_, p),] if p.kind in [Parameter.POSITIONAL_ONLY, Parameter.POSITIONAL_OR_KEYWORD]:\n",
    "                    #only one parameter, and it's positional\n",
    "                    output = module(x)\n",
    "                case {**kwargs}, _:\n",
    "                    # the dict is interpreted as kwargs\n",
    "                    output = module(**kwargs)\n",
    "                case t, _ if hasattr(t, \"_asdict\"):\n",
    "                    # the namedtuple is interpreted as kwargs\n",
    "                    output = module(**prev_output._asdict())\n",
    "                case (tuple(args), {**kwargs}), _:\n",
    "                    output = module(*args, **kwargs)\n",
    "                case tuple(args), _  :\n",
    "                    output = module(*args)\n",
    "                case x, _:\n",
    "                    output = module(x)\n",
    "        return output\n",
    "\n",
    "class GlobalEmbedding(nn.Module):\n",
    "\n",
    "    input_dim: int\n",
    "    embed_dim: int\n",
    "\n",
    "    mlp: MLP\n",
    "    r\"\"\"The MLP that changes the input features to be summed (\\phi in the paper)\"\"\"\n",
    "    activation: nn.Module\n",
    "    r\"\"\"The last activation after that MLP\"\"\"\n",
    "    aggregation: nn.Module\n",
    "    r\"\"\"The aggregation function (sum or mean. resolved using torch_geometric.nn.resolver.aggregation_resolver, so the choices are the same as in torch_geometric.nn.aggr.Multi)\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim=256, n_layers = 3, aggregation:str = \"mean\", aggregation_args={}):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.mlp = MLP(input_dim, *[hidden_dim]*n_layers, embed_dim, batchnorm=False, activation=nn.LeakyReLU)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        if \"multi\" in aggregation.lower(): \n",
    "            aggregation_args[\"mode\"]= \"proj\"\n",
    "            aggregation_args[\"mode_kwargs\"] = {\"in_channels\": embed_dim, \"out_channels\": embed_dim, **aggregation_args.get(\"mode_kwargs\", {})}\n",
    "        self.aggregation = aggregation_resolver(aggregation, **aggregation_args)\n",
    "\n",
    "    def forward(self, x: Batch):\n",
    "        node_embeddings = self.activation(self.mlp(x.data)) #n_nodes_total, key_dim\n",
    "        return self.aggregation(node_embeddings, ptr=x.ptr) #batch_size, key_dim\n",
    "\n",
    "\n",
    "class SumformerInnerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Here we implement the sumformer \"attention\" block (in quotes, because it is not really attention)\n",
    "    It is permutation-equivariant\n",
    "    and almost equivalent to a 2-step MPNN on a disconnected graph with a single witness node.\n",
    "\n",
    "    We implement the MLP-sumformer (not the polynomial sumformer). Why?\n",
    "        1. Simpler.\n",
    "        2. They do say that polynomial tends to train better at the beginning, but the MLP catches up, \n",
    "            and it’s on synthetic functions which may perform very differently from real data \n",
    "            (and gives an advantage to the polynomial sumformer, which has fewer parameters).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    input_dim: int\n",
    "    \"\"\"dimension of the input features\"\"\"\n",
    "\n",
    "    key_dim: int\n",
    "    \"\"\"Dimesion of the aggregate sigma\"\"\"\n",
    "\n",
    "    hidden_dim: int\n",
    "    \"\"\"Dimension of the hidden layers of the MLPs\"\"\"\n",
    "\n",
    "    aggreg_linear: nn.Linear\n",
    "\n",
    "    psi: MLP\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim=512, key_dim = 256 , output_dim=3, aggregation:str = \"mean\", aggregation_args={}, \n",
    "                 node_embed_n_layers=3, output_n_layers=3):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.key_dim = key_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.global_embedding = GlobalEmbedding(\n",
    "                input_dim=input_dim, embed_dim=key_dim, \n",
    "                hidden_dim=hidden_dim, n_layers=node_embed_n_layers, \n",
    "                aggregation=aggregation, aggregation_args=aggregation_args\n",
    "        ) \n",
    "\n",
    "        self.input_linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.aggreg_linear = nn.Linear(key_dim, hidden_dim)\n",
    "        self.psi = MLP(hidden_dim, *[hidden_dim]*output_n_layers, 10, \n",
    "                          batchnorm=False, activation=nn.LeakyReLU)\n",
    "\n",
    "    def forward(self, x: Tensor|Batch):\n",
    "        \"\"\"This is a faster, equivalent formulation of the sumformer attention block.\n",
    "        See my notes for the derivation (that i’ll transcribe to here at some point)\n",
    "\n",
    "        Caution! This approximation may not be exact (but should still be universal)\n",
    "        if the aggregation is not linear (ie sum or average).\n",
    "        \"\"\"\n",
    "        if isinstance(x, Tensor): x = Batch.from_unbatched(x)\n",
    "        assert isinstance(x, Batch)\n",
    "        assert x.n_features == self.input_dim\n",
    "        sigma = self.global_embedding(x)\n",
    "\n",
    "        sigma_hiddendim = self.aggreg_linear(sigma) #batch_size, hidden_dim\n",
    "        x_hiddendim = self.input_linear(x.data) #n_nodes_total, hidden_dim\n",
    "        \n",
    "        psi_input = x_hiddendim + sigma_hiddendim[x.batch, :] #n_nodes_total, hidden_dim\n",
    "        psi_input = F.leaky_relu(psi_input) #n_nodes_total, hidden_dim\n",
    "\n",
    "        return Batch.from_other(self.psi(psi_input), x) #n_nodes_total, input_dim\n",
    "\n",
    "class SumformerBlock(nn.Sequential):\n",
    "    \"\"\"\n",
    "    Inner SumformerBlock, with a residual connection and a layer norm.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *block_args, **block_kwargs):\n",
    "        super().__init__()\n",
    "        block = SumformerInnerBlock(*block_args, **block_kwargs)\n",
    "        residual_block = ResidualShortcut(block)\n",
    "        self.add_module(\"residual_block\", residual_block)\n",
    "        self.add_module(\"norm\", nn.LayerNorm(block.input_dim))\n",
    "\n",
    "class Sumformer(Repeat):\n",
    "    def __init__(self, num_blocks: int, *block_args, **block_kwargs):\n",
    "        make_block = lambda: SumformerBlock(*block_args, **block_kwargs)\n",
    "        super().__init__(num_blocks, make_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1.])\n",
      "tensor([[0.5000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3333]])\n",
      "tensor([[0.5761, 0.2119, 0.2119],\n",
      "        [0.2119, 0.2119, 0.5761]])\n"
     ]
    }
   ],
   "source": [
    "dataset = [torch.tensor([[1, 0, 0], \n",
    "            [0, 0, 1]], dtype=torch.float), \n",
    "           torch.tensor([[1, 1, 1], \n",
    "            [1, 2, 3]], dtype=torch.float)]\n",
    "print(torch.norm(dataset[0], dim=1))\n",
    "print(torch.div(dataset[0], torch.tensor([2, 3]).unsqueeze(-1)))\n",
    "print (F.softmax(dataset[0], dim=1))\n",
    "#print(torch.div(dataset[0],torch.norm(dataset[0], dim=1)))\n",
    "\n",
    "batch = Batch.from_list(dataset, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(data=tensor([[1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 2., 3.]]), order=1, indicator=BatchIndicator(n_nodes=tensor([2, 2]), n_edges=None, ptr1=None, ptr2=None, batch1=None, batch2=None, diagonal=None, transpose_indices=None))\n",
      "Batch(data=tensor([[1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 2., 3.]]), order=1, indicator=BatchIndicator(n_nodes=tensor([2, 2]), n_edges=None, ptr1=None, ptr2=None, batch1=None, batch2=None, diagonal=None, transpose_indices=None))\n"
     ]
    }
   ],
   "source": [
    "print(batch)\n",
    "batch.normalize()\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=5, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sumformer(num_blocks=1, input_dim=3, hidden_dim=20, key_dim=3)\n",
    "linear = nn.Linear(in_features = 3, out_features = 5)\n",
    "model.to('cuda:0')\n",
    "linear.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(data=tensor([[0.0446, 0.1156, 0.2075, 0.5637, 0.0686],\n",
      "        [0.2569, 0.1081, 0.2178, 0.1546, 0.2626],\n",
      "        [0.0607, 0.1271, 0.2437, 0.4806, 0.0879],\n",
      "        [0.4420, 0.0538, 0.0986, 0.0485, 0.3570]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>), order=1, indicator=BatchIndicator(n_nodes=tensor([2, 2], device='cuda:0'), n_edges=None, ptr1=tensor([0, 2, 4], device='cuda:0'), ptr2=None, batch1=tensor([0, 0, 1, 1], device='cuda:0'), batch2=None, diagonal=None, transpose_indices=None))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "batch = batch.to('cuda:0')\n",
    "out = model(batch)\n",
    "probs = F.softmax(linear(out), dim=1)\n",
    "print(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(data=tensor([[1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 2., 3.]]), order=1, indicator=BatchIndicator(n_nodes=tensor([2, 2]), n_edges=None, ptr1=tensor([0, 2, 4]), ptr2=None, batch1=tensor([0, 0, 1, 1]), batch2=None, diagonal=None, transpose_indices=None))\n",
      "torch.Size([2, 3])\n",
      "torch.Size([5, 3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(batch)\n",
    "batch.indicator\n",
    "start = 0\n",
    "for num in batch.n_nodes:\n",
    "    end = start + num\n",
    "    ptset = batch.data[start:end]\n",
    "    print(ptset.shape)\n",
    "    b_probs = probs.data[start:end]\n",
    "    \n",
    "    print(torch.mm(b_probs.T, ptset).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58607938 0.1528506 ]\n",
      " [0.95847123 0.31168894]\n",
      " [0.836457   0.9830779 ]\n",
      " [0.32845917 0.45555548]\n",
      " [0.83689396 0.35559389]\n",
      " [0.3697229  0.86049048]\n",
      " [0.8512059  0.22971335]\n",
      " [0.92234859 0.0066988 ]\n",
      " [0.72984807 0.89840314]\n",
      " [0.37502894 0.35430839]\n",
      " [0.76617551 0.19779512]\n",
      " [0.78968389 0.16864712]\n",
      " [0.72171767 0.37874082]\n",
      " [0.70169063 0.55751477]\n",
      " [0.51761923 0.65631835]\n",
      " [0.15445026 0.87729761]\n",
      " [0.42434019 0.86491709]\n",
      " [0.66051889 0.17870329]\n",
      " [0.20330657 0.7728875 ]\n",
      " [0.14385089 0.44179211]\n",
      " [0.07265356 0.56502268]\n",
      " [0.35568253 0.03984401]\n",
      " [0.51125517 0.55209259]\n",
      " [0.87119226 0.42437854]\n",
      " [0.61632771 0.58700833]\n",
      " [0.25267784 0.07193735]\n",
      " [0.74810602 0.17122641]\n",
      " [0.30043845 0.60265021]\n",
      " [0.32310421 0.13110836]\n",
      " [0.05549359 0.60915485]\n",
      " [0.83762695 0.42213959]\n",
      " [0.52746938 0.88113292]\n",
      " [0.56956314 0.17724093]\n",
      " [0.98072008 0.8517689 ]\n",
      " [0.42008371 0.40821963]\n",
      " [0.70841029 0.88022145]\n",
      " [0.82401381 0.52359692]\n",
      " [0.65264608 0.27955114]\n",
      " [0.76541357 0.77453099]\n",
      " [0.72382187 0.7132233 ]\n",
      " [0.80190441 0.45555923]\n",
      " [0.69781845 0.7072229 ]\n",
      " [0.26168893 0.9315956 ]\n",
      " [0.48438802 0.58097888]\n",
      " [0.10175886 0.21093701]\n",
      " [0.4551838  0.06035315]\n",
      " [0.60825681 0.06104277]\n",
      " [0.77687746 0.38673404]\n",
      " [0.77735285 0.99134422]\n",
      " [0.74871528 0.55989983]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "array = np.load('/data/riley/for_sam/50_uniform_points.npy')\n",
    "print(array[0][:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "model_params = {}\n",
    "widths = [16, 32, 48, 64, 80, 96]\n",
    "for w in widths:\n",
    "    mname = f'depth-{2}-ed-{16}-hd-{w}-od-{w}'\n",
    "    model_params[mname] = {'depth': 3,\n",
    "                           'embedding_dim': 16,\n",
    "                           'hidden_dim': w,\n",
    "                            'output_dim': w,\n",
    "                            'input_dim': 3\n",
    "                           }\n",
    "\n",
    "file=open(\"model-configs/change-output-dim-1-in-dim-3.yml\",\"w\")\n",
    "yaml.dump(model_params,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "array = np.load('/data/riley/for_sam/ply_data_train0_CH.npy')\n",
    "\n",
    "downsampled_samples = []\n",
    "for i in range(array.shape[0]):\n",
    "    pt_set = array[i]\n",
    "    idx = np.random.choice(np.arange(array.shape[1]), size=50)\n",
    "    new_pt_set = pt_set[idx, :3]\n",
    "    chull = ConvexHull(new_pt_set)\n",
    "    verts = chull.vertices\n",
    "\n",
    "    chull_col = np.zeros(50)\n",
    "    chull_col[verts] = 1.0\n",
    "    chull_col = np.expand_dims(chull_col, axis=1)\n",
    "    sample = np.concatenate((new_pt_set, chull_col), axis=1)\n",
    "    downsampled_samples.append(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m/data/sam/coreset/data/50_mnet.npy\u001b[39m\u001b[39m'\u001b[39m, downsampled_samples)\n",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m/data/sam/coreset/data/50_mnet.npy\u001b[39m\u001b[39m'\u001b[39m, downsampled_samples)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10-coreset/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10-coreset/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.save('/data/sam/coreset/data/50_mnet.npy', downsampled_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10-coreset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e071539cccef4c0bb4ed46693789f6471484fd3e421d82529124a3bb2524ec50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
